{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13018d08-c259-4e4f-b733-96c62e8cae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\REVAT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "path=os.getcwd()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bdd95d7-adb1-4914-889b-a32ff3539c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##def makeStopWords():\n",
    "stopWords=[]\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_Auditor.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_Currencies.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_DatesandNumbers.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_Generic.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_GenericLong.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_Geographic.txt\",\"r\").readlines())\n",
    "stopWords.extend(open(f\"{path}\\StopWords\\StopWords_Names.txt\",\"r\").readlines())\n",
    "for i in range(len(stopWords)):\n",
    "    stopWords[i].replace(\"\\n\",\" \")\n",
    "    v=stopWords[i].find(\"|\")\n",
    "    stopWords[i]=stopWords[i][:v]\n",
    "    try:\n",
    "        stopWords=stopWords.remove('')\n",
    "    except:\n",
    "        a=0\n",
    "    stopWords[i]=stopWords[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b472aae-0328-4527-a5f6-bc57450d0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(f\"{path}\\Output Data Structure.xlsx\")\n",
    "urlid=np.array(df.URL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "953f5f9e-1df9-4909-8292-3adb2751cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWords(urlid : str ):\n",
    "        with open(f\"{path}\\\\Web scrapping\\\\{urlid}.txt\",\"r\",errors=\"ignore\") as file:\n",
    "            words=[]\n",
    "            lines=file.readlines()\n",
    "            for j in range(len(lines)):\n",
    "                words.extend(lines[j].replace(\"\\n\",\" \").split())\n",
    "            filtered_words=[]\n",
    "            for k in range(len(words)):\n",
    "                words[k]=re.sub(r'[^\\w\\s]', '', words[k]).strip()\n",
    "                if words[k] not in stopWords:\n",
    "                    filtered_words.append(words[k])\n",
    "            filtered_words = list(filter(None, filtered_words))\n",
    "        return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c70fcd3e-8db7-4a07-b2a4-d1a9d8af3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noOfSentence(urlid :str):\n",
    "    with open(f\"{path}\\\\Web scrapping\\\\{urlid}.txt\",\"r\",errors=\"ignore\") as file:\n",
    "        content=file.read()\n",
    "        number_of_sentences = sent_tokenize(content)\n",
    "        return len(number_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "092b7dfd-24a7-44c0-b64c-a2af7acc106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouns(urlid:str):\n",
    "    count=0\n",
    "    with open(f\"{path}\\\\Web scrapping\\\\{urlid}.txt\",\"r\",errors=\"ignore\") as file:\n",
    "        content=file.read()\n",
    "        for i in [\"I\", \"we\" ,\"my\" ,\"ours\" , \"us\"]:\n",
    "            count+=len(re.findall(f\"^\\s{i}\\s$\",content))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a65997-d698-4059-b0c8-26d2d07ca3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllableCount(word):\n",
    "        count = 0\n",
    "        vowels = \"aeiou\"\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "                if word.endswith(\"e\"):\n",
    "                    count -= 1\n",
    "                elif word.endswith(\"ed\"):\n",
    "                    count -= 1\n",
    "                elif word.endswith(\"es\"):\n",
    "                    count -= 1\n",
    "        if count <= 0 :\n",
    "            count =1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8c4970-4fa5-4695-adbe-4598c70b9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeWords=open(f\"{path}\\\\MasterDictionary\\\\negative-words.txt\",\"r\").readlines()\n",
    "for i in range(len(negativeWords)):\n",
    "    negativeWords[i]=negativeWords[i].replace(\"\\n\",\" \").strip()\n",
    "positiveWords=open(f\"{path}\\\\MasterDictionary\\\\positive-words.txt\",\"r\").readlines()\n",
    "for i in range(len(positiveWords)):\n",
    "    positiveWords[i]=positiveWords[i].replace(\"\\n\",\" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f33a9e9-1f15-4bd6-815e-4022d9050991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveOutput():\n",
    "    for fileInput in range(len(urlid)):\n",
    "        if fileInput not in [35,48]:\n",
    "            words=filterWords(urlid[fileInput])\n",
    "            df[\"WORD COUNT\"][fileInput]=len(words)\n",
    "            positive=0\n",
    "            negative=0\n",
    "            for word in words:\n",
    "                if word in positiveWords:\n",
    "                    positive+=1\n",
    "                if word in negativeWords:\n",
    "                    negative+=1\n",
    "            df[\"POSITIVE SCORE\"][fileInput]=positive\n",
    "            df[\"NEGATIVE SCORE\"][fileInput]=negative\n",
    "            polarity=(positive-negative)/ ((positive + negative) + 0.000001)\n",
    "            df[\"POLARITY SCORE\"][fileInput]=polarity\n",
    "            subjectivity= (positive + negative)/ ((len(words) + 0.000001))\n",
    "            df[\"SUBJECTIVITY SCORE\"][fileInput]=subjectivity\n",
    "            df[\"AVG NUMBER OF WORDS PER SENTENCE\"][fileInput]=len(words)/noOfSentence(urlid[fileInput])\n",
    "            avgSentenceLength=len(words)/noOfSentence(urlid[fileInput])\n",
    "            df[\"AVG SENTENCE LENGTH\"][fileInput]=avgSentenceLength\n",
    "            df[\"PERSONAL PRONOUNS\"][fileInput]=pronouns(urlid[fileInput])\n",
    "            char=0\n",
    "            for word in words:\n",
    "                char+=len(word)\n",
    "            df[\"AVG WORD LENGTH\"][fileInput]=char/len(words)\n",
    "            totalSyllable=0\n",
    "            for word in words:\n",
    "                totalSyllable+=syllableCount(word)\n",
    "            df[\"SYLLABLE PER WORD\"][fileInput]=totalSyllable/len(words)\n",
    "            complexWords=0\n",
    "            for word in words:\n",
    "                if syllableCount(word)>2:\n",
    "                    complexWords+=1\n",
    "            df[\"COMPLEX WORD COUNT\"][fileInput]=complexWords\n",
    "            percentageComplex=(complexWords/len(words))*100\n",
    "            df[\"PERCENTAGE OF COMPLEX WORDS\"][fileInput]=percentageComplex\n",
    "            df[\"FOG INDEX\"][fileInput]=0.4 * (avgSentenceLength + percentageComplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2c1a092-0008-4ae5-a27b-3749df0db1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "giveOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b237c066-88ce-4e33-85d6-cd80b5cc3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Output Data Structure\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
